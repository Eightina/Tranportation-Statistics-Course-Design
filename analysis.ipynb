{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from myutils.process_utils import process_linedf, post_process, process_timetable\n",
    "from myutils.analysis_utils import load_daydf, load_routinedf, map_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = 7\n",
    "nidx = 0\n",
    "direction = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for date in ['06','07','08','09','10']:\n",
    "#     up_res = pd.DataFrame()\n",
    "#     down_res = pd.DataFrame()\n",
    "#     gps = load_daydf(int(date))\n",
    "#     for nidx in gps.nidx.unique():\n",
    "#         print(nidx)\n",
    "#         for direction in [0, 1]:\n",
    "#             routine = load_routinedf(gps, nidx, direction)\n",
    "#             # if direction == 0:\n",
    "#             #     if ''routine['station_status'][0]\n",
    "#             routine = post_process(routine, date=int(date))\n",
    "#             routine = routine[['vid','time','direction','nidx', \n",
    "#                                 'deadheading','cum_length', 'velocity','station_status']]\n",
    "#             base_data = routine.drop('time', axis = 1).groupby(['nidx','direction','station_status']).agg('mean')\n",
    "#             time_data = routine.groupby(['nidx','direction','station_status'])['time'].agg(['min','max'])\n",
    "#             routine = pd.merge(base_data, time_data,left_index=True, right_index=True).sort_values('max').reset_index()\n",
    "#             if direction == 0:\n",
    "#                 up_res = pd.concat([up_res, routine], ignore_index=True).reset_index(drop = True)\n",
    "#             else:\n",
    "#                 down_res = pd.concat([down_res, routine], ignore_index=True).reset_index(drop = True)\n",
    "#     up_res.to_pickle('./data/analysis/'+'truetime_up_09'+date+'.pkl')\n",
    "#     down_res.to_pickle('./data/analysis/'+'truetime_down_09'+date+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ass = pd.read_pickle('./data/analysis/as_6.pkl')\n",
    "# base_data = ass.drop('time', axis = 1).groupby(['nidx','direction','station_status']).agg('mean')\n",
    "# time_data = ass.groupby(['nidx','direction','station_status'])['time'].agg(['min','max'])\n",
    "# ass = pd.merge(base_data, time_data,left_index=True, right_index=True)\n",
    "# ass.reset_index()\n",
    "# # ass.groupby()\n",
    "# ass.groupby()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ass = pd.read_pickle('./data/analysis/truetime_up_0906.pkl')\n",
    "# new_ass.set_index(['station_status']).loc['菊园车站']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = load_daydf(date)\n",
    "routine = load_routinedf(day, nidx, direction)\n",
    "mapline = process_linedf(direction)\n",
    "xlim = (7800+1.349e7, 8700+1.349e7)\n",
    "ylim = (3.679e6, 3.682e6)\n",
    "map_plot(mapline, routine)\n",
    "map_plot(mapline, routine, xlim, ylim)\n",
    "\n",
    "station_time_res = routine.loc[routine['station_status'] != 0, ['time','cum_length', 'station_status']].groupby('station_status').agg('mean').sort_values('time')\n",
    "len(station_time_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(day.time.min(), day.time.max()) \n",
    "fig, ax = plt.subplots(dpi=300, figsize = (15,6))\n",
    "for nidx in day.nidx.unique():\n",
    "    routine = load_routinedf(day, nidx, direction)\n",
    "    routine = post_process(routine, date=date)\n",
    "    if len(routine) > 0:\n",
    "        if routine.deadheading[0] == 0:\n",
    "            ax.plot(routine.time, routine.cum_length, color = 'green')\n",
    "        else:\n",
    "            ax.plot(routine.time, routine.cum_length, color = 'red')\n",
    "        \n",
    "# ax.plot(routine1.time, routine1.cum_length)\n",
    "# ax.plot(routine2.time, routine2.cum_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 分析首末班车发车准点率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time_lolim = timetable_up['start_time_lolim']\n",
    "# start_time_hilim = timetable_up['start_time_hilim']\n",
    "# maxtime = truetime_up['max'][0]\n",
    "# start_tar = timetable_up.loc[\n",
    "#             (\n",
    "#                 (start_time_lolim <= maxtime) \n",
    "#                 & (start_time_hilim >= maxtime)\n",
    "#             )\n",
    "#     ].reset_index(drop = True)\n",
    "# start_tar['start_time_lolim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "def time_matching(truetime_row, timetabledf):\n",
    "    mintime = truetime_row['min']\n",
    "    maxtime = truetime_row['max']\n",
    "    start_time_lolim = timetabledf['start_time_lolim']\n",
    "    start_time_hilim = timetabledf['start_time_hilim']\n",
    "    end_time_lolim = timetabledf['end_time_lolim']\n",
    "    end_time_hilim = timetabledf['end_time_hilim']\n",
    "    \n",
    "    start_tar = timetabledf.loc[\n",
    "                (\n",
    "                    (start_time_lolim <= maxtime) \n",
    "                    & (start_time_hilim >= maxtime)\n",
    "                )\n",
    "        ].reset_index(drop = True)\n",
    "    end_tar = timetabledf.loc[\n",
    "                (\n",
    "                    ( end_time_lolim <= mintime) \n",
    "                    & ( end_time_hilim >= mintime)\n",
    "                )\n",
    "        ].reset_index(drop = True)\n",
    "    \n",
    "    if truetime_row['direction'] == 0:\n",
    "        if truetime_row['station_status'] == '菊园车站':\n",
    "            if len(start_tar) > 0:\n",
    "                truetime_row['intime'] = True\n",
    "                truetime_row['lolim'] = start_tar['start_time_lolim'][0]\n",
    "                truetime_row['hilim'] = start_tar['start_time_hilim'][0]\n",
    "        else:\n",
    "            if len(end_tar) > 0:\n",
    "                truetime_row['intime'] = True\n",
    "                truetime_row['lolim'] = end_tar['end_time_lolim'][0]\n",
    "                truetime_row['hilim'] = end_tar['end_time_lolim'][0]\n",
    "    else:\n",
    "        if truetime_row['station_status'] == '公交嘉定新城站':\n",
    "            if len(start_tar) > 0:\n",
    "                truetime_row['intime'] = True\n",
    "                truetime_row['lolim'] = start_tar['start_time_lolim'][0]\n",
    "                truetime_row['hilim'] = start_tar['start_time_hilim'][0]\n",
    "        else:\n",
    "            if len(end_tar) > 0:\n",
    "                truetime_row['intime'] = True\n",
    "                truetime_row['lolim'] = end_tar['end_time_lolim'][0]\n",
    "                truetime_row['hilim'] = end_tar['end_time_lolim'][0]\n",
    "    \n",
    "    return truetime_row\n",
    "\n",
    "\n",
    "def generate_intime(date='06', time_range=[0, 0, 23, 59]):\n",
    "    # for date in ['06','07','08','09','10']:\n",
    "    lolim = dt(2021, 9 , int(date), hour=int(time_range[0]),minute=int(time_range[1]),second=0)\n",
    "    hilim = dt(2021, 9 , int(date), hour=int(time_range[2]),minute=int(time_range[3]),second=0)\n",
    "    \n",
    "    path_timetable = './data/timetable/'\n",
    "    timetable_up = pd.read_csv(path_timetable + 'timetable_up_09' + date + '.csv')\n",
    "    timetable_up = process_timetable(timetable_up, int(date), strict = False)\n",
    "    timetable_down = pd.read_csv(path_timetable + 'timetable_down_09' + date + '.csv')\n",
    "    timetable_down = process_timetable(timetable_down, int(date), strict = False)\n",
    "    \n",
    "    path_truetime = './data/analysis/'\n",
    "    truetime_up = pd.read_pickle(path_truetime + 'truetime_up_09' + date + '.pkl')\n",
    "    truetime_up = truetime_up.loc[(\n",
    "            ((truetime_up['station_status'] == '公交嘉定新城站') | (truetime_up['station_status'] == '菊园车站'))\n",
    "            & ((truetime_up['max'] >= lolim) & (truetime_up['max'] <= hilim))\n",
    "        )]\n",
    "    truetime_up['intime'] = [False for _ in range(len(truetime_up))]\n",
    "    truetime_up['lolim'] = [None for _ in range(len(truetime_up))]\n",
    "    truetime_up['hilim'] = [None for _ in range(len(truetime_up))]\n",
    "    \n",
    "    truetime_down = pd.read_pickle(path_truetime + 'truetime_down_09' + date + '.pkl')\n",
    "    truetime_down = truetime_down.loc[(\n",
    "            ((truetime_down['station_status'] == '公交嘉定新城站') | (truetime_down['station_status'] == '菊园车站'))\n",
    "            & ((truetime_down['max'] >= lolim) & (truetime_down['max'] <= hilim))\n",
    "        )]\n",
    "    truetime_down['intime'] = [False for _ in range(len(truetime_down))]\n",
    "    truetime_down['lolim'] = [None for _ in range(len(truetime_down))]\n",
    "    truetime_down['hilim'] = [None for _ in range(len(truetime_down))]\n",
    "    \n",
    "    truetime_up = truetime_up.apply(\n",
    "        time_matching, \n",
    "        args=(timetable_up,),\n",
    "        # result_type='broadcast',\n",
    "        axis = 1,\n",
    "        )\n",
    "    truetime_down = truetime_down.apply(\n",
    "        time_matching, \n",
    "        args=(timetable_down,), \n",
    "        # result_type='broadcast',\n",
    "        axis = 1,\n",
    "        )\n",
    "    \n",
    "    return truetime_up,truetime_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truetime_down = pd.read_pickle('./data/analysis/' + 'truetime_down_09' + '06' + '.pkl')\n",
    "truetime_down.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timetable_up,timetable_down,truetime_up,truetime_down = generate_intime(date='06', time_range=[0, 0, 23, 59])\n",
    "truetime_up,truetime_down = generate_intime(date='10', time_range=[0, 0, 23, 59])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_start_intime = truetime_up.loc[(truetime_up['station_status'] == '菊园车站') & (truetime_up['intime'])]\n",
    "print(up_start_intime.intime.sum()/len(truetime_up.loc[truetime_up['station_status'] == '菊园车站']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_start_intime = truetime_down.loc[(truetime_down['station_status'] == '公交嘉定新城站') & (truetime_down['intime'])]\n",
    "print(down_start_intime.intime.sum()/len(truetime_down.loc[truetime_down['station_status'] == '公交嘉定新城站']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_end_intime = truetime_up.loc[(truetime_up['station_status'] == '公交嘉定新城站') & (truetime_up['intime'])]\n",
    "down_end_intime = truetime_up.loc[(truetime_down['station_status'] == '菊园车站') & (truetime_down['intime'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "first_start_timetable = pd.DataFrame()\n",
    "last_start_timetable = pd.DataFrame()\n",
    "first_start_direction_list = []\n",
    "last_start_direction_list = []\n",
    "first_start_date_list = []\n",
    "last_start_date_list = []\n",
    "first_start_time_list = []\n",
    "last_start_time_list = []\n",
    "for date in [6,\n",
    "            7,\n",
    "            8,\n",
    "            9,\n",
    "            10,\n",
    "            ]:\n",
    "    day = load_daydf(date)\n",
    "    hilim = pd.Timestamp(dt(2021,9,date, hour=23,minute=59,second=59))\n",
    "    lolim = pd.Timestamp(dt(2021,9,date, hour=4,minute=0,second=0))\n",
    "    day = day.drop(day.loc[(day['time'] > hilim) | (day['time'] < lolim)].index,\n",
    "                    axis = 0\n",
    "                ).reset_index(drop=True)\n",
    "    for direction in [0, 1]:\n",
    "        if direction == 0:\n",
    "            direc_str = 'up'\n",
    "            start_timetable = day.loc[(day['direction']==direction) & (day['station_status']=='菊园车站')].groupby(['nidx','station_status'])['time'].agg(['max'])\n",
    "        else:\n",
    "            direc_str = 'down'\n",
    "            start_timetable = day.loc[(day['direction']==direction) & (day['station_status']=='公交嘉定新城站')].groupby(['nidx','station_status'])['time'].agg(['max'])\n",
    "        # if len(start_timetable)\n",
    "        first_start_time_list.append(start_timetable.min())\n",
    "        last_start_time_list.append(start_timetable.max())\n",
    "        first_start_date_list.append(date)\n",
    "        last_start_date_list.append(date)\n",
    "        first_start_direction_list.append(direction)\n",
    "        last_start_direction_list.append(direction)\n",
    "        # print(str(date) + ':\\n' + str(start_timetable.min()) + '\\n' +  str(start_timetable.max()))\n",
    "first_start_timetable = pd.DataFrame({'date':first_start_date_list,\n",
    "                                        'direction':first_start_direction_list,\n",
    "                                        'time':first_start_time_list})\n",
    "last_start_timetable = pd.DataFrame({'date':last_start_date_list,\n",
    "                                        'direction':last_start_direction_list,\n",
    "                                        'time':last_start_time_list})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_up_timetable = pd.concat([first_start_timetable.loc[first_start_timetable['direction']==0], last_start_timetable.loc[last_start_timetable['direction']==0]])\n",
    "real_down_timetable = pd.concat([first_start_timetable.loc[first_start_timetable['direction']==1], last_start_timetable.loc[last_start_timetable['direction']==1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_up_timetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_down_timetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_first_start_timetable = pd.DataFrame()\n",
    "standard_last_start_timetable = pd.DataFrame()\n",
    "standard_first_start_direction_list = []\n",
    "standard_last_start_direction_list = []\n",
    "standard_first_start_date_list = []\n",
    "standard_last_start_date_list = []\n",
    "standard_first_start_time_list = []\n",
    "standard_last_start_time_list = []\n",
    "for date in ['06',\n",
    "            '07',\n",
    "            '08',\n",
    "            '09',\n",
    "            '10',\n",
    "            ]:\n",
    "    path = './data/timetable/'\n",
    "    up = pd.read_csv(path + 'timetable_up_09'+date+'.csv')\n",
    "    up = process_timetable(up)\n",
    "    down = pd.read_csv(path + 'timetable_down_09'+date+'.csv')\n",
    "    down = process_timetable(down)\n",
    "    for i, real_up_row in real_up_timetable.iterrows():\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, real_time_row in first_start_timetable.iterrows():\n",
    "    for j, standard_time_row in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up = process_timetable(up, int(date))\n",
    "up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up.start_time[0].split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_timetable = day.loc[(day['direction']==0) & (day['station_status'] == '菊园车站')].groupby(['nidx','station_status'])['time'].agg(['min','max'])\n",
    "real_timetable = real_timetable.sort_values('max',ascending = True)\n",
    "real_timetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(day.nidx.unique())):\n",
    "    marker = day.loc[day['nidx']==i]['deadheading'].reset_index(drop=True)\n",
    "    if len(marker) > 1:\n",
    "        if marker[0] == 1:\n",
    "            print('\\n dead heading')\n",
    "        print(real_timetable.loc[i].sort_values('min'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e9c953ce333e46b732450a2d7281e263005e5cbdd37c84ada0757df85e40195"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
